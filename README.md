# ðŸš› FleetPred â€” ManutenÃ§Ã£o Preditiva de Frota

> AvaliaÃ§Ã£o IntermediÃ¡ria Â· IA Generativa Â· UniSENAI

**Endpoint:** (https://f6bf-179-48-116-161.ngrok-free.app/)
**RepositÃ³rio:** https://github.com/RoseBorges44/fleetpred

---

## O Problema

Quem trabalha com gestÃ£o de frota pesada sabe: manutenÃ§Ã£o corretiva Ã© o pesadelo. Um caminhÃ£o que quebra na estrada nÃ£o Ã© sÃ³ o custo do reparo â€” Ã© frete atrasado, multa contratual, motorista parado, guincho, e Ã s vezes perda de carga. Na prÃ¡tica, a maioria das frotas ainda funciona no modo reativo: quebrou, conserta. Ou no melhor caso, troca Ã³leo e filtro a cada X km e torce pro resto.

O FleetPred Ã© um sistema de manutenÃ§Ã£o preditiva que tenta resolver isso. A ideia Ã© simples: o tÃ©cnico reporta sintomas (vibraÃ§Ã£o, temperatura alta, ruÃ­do), o sistema cruza com o histÃ³rico daquele veÃ­culo e de veÃ­culos parecidos na frota, e gera um diagnÃ³stico com probabilidade de falha, prazo estimado e recomendaÃ§Ã£o de aÃ§Ã£o.

Nessa versÃ£o (intermediÃ¡ria), a parte da IA estÃ¡ mockada â€” as respostas de diagnÃ³stico sÃ£o simuladas. Mas o mock jÃ¡ retorna JSON estruturado no formato exato que o LLM vai retornar na versÃ£o final, via function calling ou structured output.

### Por que esse problema?

Tenho familiaridade com manutenÃ§Ã£o de ativos mÃ³veis e o domÃ­nio de frotas pesadas. ConheÃ§o o dia a dia: tÃ©cnico que descreve problema de um jeito, mecÃ¢nico que interpreta de outro, gestor que precisa decidir qual caminhÃ£o parar primeiro. O sistema tenta formalizar esse fluxo e dar visibilidade sobre a saÃºde da frota toda num lugar sÃ³.

---

## Como a IA vai ser integrada (versÃ£o final)

Hoje o arquivo `backend/mock_ai.py` tem um mapeamento estÃ¡tico de diagnÃ³sticos por sistema e sintoma. Na versÃ£o final, esse mÃ³dulo vai ser substituÃ­do por chamadas Ã  API de um LLM (provavelmente Claude via Anthropic SDK). O modelo vai receber:

- Os sintomas que o tÃ©cnico reportou
- HistÃ³rico de manutenÃ§Ãµes daquele veÃ­culo (puxado do SQLite)
- Dados de saÃºde dos componentes
- PadrÃµes de falha de veÃ­culos com perfil parecido na frota

E vai retornar um JSON com probabilidade, horizonte de falha, peÃ§as sugeridas e economia estimada. O formato jÃ¡ tÃ¡ definido no mock â€” foi pensado pra ser o schema do structured output.

Exemplo do que o mock retorna hoje (e que o LLM vai retornar depois):

```json
{
  "componente": "Sistema de Arrefecimento",
  "probabilidade_falha": 0.82,
  "horizonte_dias": 12,
  "severidade": "alta",
  "pecas_sugeridas": ["VÃ¡lvula termostÃ¡tica", "Mangueira superior"],
  "economia_estimada": 5800,
  "base_historica": "3 veÃ­culos similares falharam com sintomas idÃªnticos"
}
```

Isso nÃ£o Ã© texto livre â€” Ã© dado estruturado que alimenta o calendÃ¡rio de manutenÃ§Ã£o, calcula ROI e prioriza a fila.

---

## Escolhas de Design

### FastAPI + React + SQLite

**FastAPI:** preciso servir JSON pro frontend e, no futuro, fazer chamadas assÃ­ncronas pra API do LLM. FastAPI tem async nativo e valida dados com Pydantic â€” importa porque o diagnÃ³stico da IA vai vir como JSON tipado. Considerei Flask, mas perdia a validaÃ§Ã£o automÃ¡tica e os docs gerados no `/docs` (ajudaram bastante no desenvolvimento pra testar as rotas).

**React + Vite:** o sistema tem 6 telas com navegaÃ§Ã£o, formulÃ¡rios dinÃ¢micos e grÃ¡ficos. Pensei em Streamlit no comeÃ§o â€” seria mais rÃ¡pido â€” mas Streamlit nÃ£o lida bem com navegaÃ§Ã£o entre pÃ¡ginas nem com formulÃ¡rios condicionais (os sintomas mudam dependendo do sistema selecionado). AlÃ©m disso, React + API se integra melhor com LLM no futuro: o backend chama o modelo e devolve resultado, frontend nem sabe como foi gerado.

**SQLite:** zero configuraÃ§Ã£o, Ã© um arquivo. Pra 10-50 caminhÃµes com histÃ³rico, aguenta tranquilo. Em produÃ§Ã£o com mÃºltiplos usuÃ¡rios simultÃ¢neos migraria pra Postgres, mas pro protÃ³tipo Ã© pragmatismo.

### Tema escuro

NÃ£o Ã© estÃ©tica. Interfaces de monitoramento (centro de controle, sala de operaÃ§Ãµes) usam tema escuro porque o operador fica olhando pra tela por horas. Fundo escuro reduz fadiga visual e faz os indicadores de cor (verde/amarelo/vermelho) saltarem mais. O gestor precisa bater o olho e em 2 segundos saber quantos caminhÃµes estÃ£o crÃ­ticos.

### SemÃ¡foro de cores (verde/amarelo/vermelho)

Qualquer pessoa de operaÃ§Ã£o entende sem treinamento. A decisÃ£o mais urgente na gestÃ£o de frota Ã©: "qual caminhÃ£o eu paro primeiro?". O cÃ³digo de cores responde isso instantaneamente.

### FormulÃ¡rio condicional

Essa decisÃ£o vem do domÃ­nio. TÃ©cnico reportando motor nÃ£o tem os mesmos sintomas que tÃ©cnico reportando freio. Lista Ãºnica com 25 sintomas = formulÃ¡rio inutilizÃ¡vel = tÃ©cnico preenchendo qualquer coisa. Separando por sistema, o formulÃ¡rio fica objetivo e os dados jÃ¡ chegam categorizados pra IA.

### Sidebar fixa

Considerei tabs no topo, mas com 6 telas fica apertado e nÃ£o escala (se adicionar estoque de peÃ§as, motoristas, rotas...). Sidebar Ã© padrÃ£o de ERP e sistemas de gestÃ£o porque permite navegar rÃ¡pido sem perder contexto.

### 6 tabelas no banco

OcorrÃªncia, diagnÃ³stico e manutenÃ§Ã£o sÃ£o entidades diferentes com ciclos de vida diferentes. TÃ©cnico registra ocorrÃªncia (imediato), IA gera diagnÃ³stico (processamento), gestor agenda manutenÃ§Ã£o (decisÃ£o). Juntar tudo numa tabela ia criar acoplamento e dificultar rastreabilidade. Alertas ficam separados porque podem vir de diagnÃ³sticos da IA ou de regras simples (ex: km desde Ãºltimo Ã³leo > 15.000).

### Mock com JSON estruturado

O mock nÃ£o retorna texto livre. Retorna dict com campos tipados: probabilidade (float), horizonte (int), peÃ§as (array), economia (float). Simula exatamente o que vou pedir ao LLM via structured output. Quando trocar o mock pelo LLM, o resto do sistema nÃ£o muda â€” sÃ³ a fonte do diagnÃ³stico. Esse era o objetivo.

---

## O que Funcionou

### Agente de codificaÃ§Ã£o

Usei Claude Code pra gerar a maior parte do cÃ³digo.

**Estrutura do projeto:** pedi a estrutura de pastas e arquivos base. Veio certo de primeira â€” separaÃ§Ã£o backend/frontend, imports corretos, tudo no lugar.

**CSS e tema:** o tema escuro com variÃ¡veis CSS ficou consistente. Pedi uma vez e ele manteve a mesma paleta em todos os componentes.

**GrÃ¡ficos:** pedi os grÃ¡ficos de tendÃªncia e custo com Recharts. Gerou com tooltip, legend e cores corretas. Economizou tempo porque a configuraÃ§Ã£o do Recharts Ã© bem verbosa.

**Schema do banco:** descrevi as tabelas em linguagem natural e gerou SQL com constraints (CHECK, FK) adequadas.

**Prompt que funcionou bem:**

Pedir incrementalmente â€” uma camada por vez (banco primeiro, depois rotas, depois frontend base, depois tela por tela) â€” deu resultados muito melhores do que pedir tudo junto.

---

## O que NÃ£o Funcionou

**Proxy do Vite:** o agente nÃ£o configurou o `allowedHosts` no Vite pra funcionar com ngrok. Dava erro de "Blocked request" atÃ© adicionar `allowedHosts: true` e `host: true` manualmente no `vite.config.js`.

**Datas hardcoded no seed:** as manutenÃ§Ãµes agendadas tinham datas fixas. Tive que conferir se estavam na semana corrente pro calendÃ¡rio nÃ£o ficar vazio.

**Prompt genÃ©rico:** quando pedi "faÃ§a o frontend completo" num prompt sÃ³, o resultado veio desorganizado. Funcionou muito melhor pedindo uma tela por vez.

**O que faria diferente:** teria planejado os mocks de dados com mais cuidado antes de comeÃ§ar. Perdi tempo ajustando dados que nÃ£o faziam sentido no contexto.

---

## Uso do Agente de CodificaÃ§Ã£o

**Ferramenta:** Claude Code (CLI)

**Processo:** comecei com um esboÃ§o das telas antes de pedir cÃ³digo. Depois fui incrementalmente: backend primeiro (banco, seed, rotas), depois frontend tela por tela. Commit a cada mÃ³dulo.

**Prompts usados (resumo):**

1. Estrutura do projeto + schema do banco + seed data + mock IA
2. Rotas da API (5 arquivos de rotas separados)
3. Frontend base (layout, sidebar, CSS, api service)
4. Dashboard + Ficha do VeÃ­culo
5. FormulÃ¡rio de OcorrÃªncia (com campos condicionais)
6. DiagnÃ³stico IA + Plano de ManutenÃ§Ã£o + RelatÃ³rios
7. Ajustes finais (start.sh, gitignore)

**ProporÃ§Ã£o:**
- Gerado pelo agente: ~80%
- Ajustado manualmente: ~15%
- Escrito do zero: ~5%

---

## Como Executar

**PrÃ©-requisitos:** Python 3.10+ e Node.js 18+

```bash
git clone https://github.com/RoseBorges44/fleetpred.git
cd fleetpred

# Terminal 1 â€” Backend:
cd backend
pip install -r requirements.txt
uvicorn main:app --reload --port 8000

# Terminal 2 â€” Frontend:
cd frontend
npm install
npm run dev

# Terminal 3 â€” Expor publicamente:
ngrok http 5173
```

**Acessar:** http://localhost:5173 (frontend) Â· http://localhost:8000/docs (API)

---

## Estrutura do Projeto

```
fleetpred/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # App FastAPI, CORS, registro de rotas
â”‚   â”œâ”€â”€ database.py          # Schema SQLite â€” 6 tabelas
â”‚   â”œâ”€â”€ seed_data.py         # 10 caminhÃµes com dados realistas
â”‚   â”œâ”€â”€ mock_ai.py           # DiagnÃ³stico simulado (substituir por LLM)
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ routes/
â”‚       â”œâ”€â”€ veiculos.py      # Dashboard stats, lista, detalhe
â”‚       â”œâ”€â”€ ocorrencias.py   # Registro + geraÃ§Ã£o de diagnÃ³stico
â”‚       â”œâ”€â”€ manutencoes.py   # Agendadas + fila de prioridade
â”‚       â”œâ”€â”€ relatorios.py    # Custos, disponibilidade, tendÃªncia
â”‚       â””â”€â”€ alertas.py       # Alertas + diagnÃ³stico detalhado
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ App.jsx          # Sidebar + rotas React Router
â”‚       â”œâ”€â”€ index.css        # Tema escuro com CSS variables
â”‚       â”œâ”€â”€ services/api.js  # Camada de comunicaÃ§Ã£o com API
â”‚       â””â”€â”€ pages/           # 6 telas da aplicaÃ§Ã£o
â”œâ”€â”€ prompts/                 # System prompt (pra versÃ£o final)
â”œâ”€â”€ tools/                   # DefiniÃ§Ã£o de ferramentas (pra versÃ£o final)
â”œâ”€â”€ start.sh
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## PrÃ³ximos Passos (versÃ£o final)

- Trocar `mock_ai.py` por chamadas reais via Anthropic SDK
- System prompt com persona de especialista em manutenÃ§Ã£o de frota
- Tools: consultar histÃ³rico, buscar padrÃµes na frota, calcular economia
- Temperatura baixa (diagnÃ³stico precisa de consistÃªncia, nÃ£o criatividade)
- Documentar todas as decisÃµes de engenharia de LLM
