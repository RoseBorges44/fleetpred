# ğŸš› FleetPred â€” ManutenÃ§Ã£o Preditiva de Frota com IA Multi-Agente

> AvaliaÃ§Ã£o Final Â· IA Generativa Â· UniSENAI

**RepositÃ³rio:** https://github.com/RoseBorges44/fleetpred

**Acesse em:** http://192.168.0.121:5173/

---

## O Problema

Quem trabalha com gestÃ£o de frota pesada sabe: manutenÃ§Ã£o corretiva Ã© o pesadelo. Um caminhÃ£o que quebra na estrada nÃ£o Ã© sÃ³ o custo do reparo â€” Ã© frete atrasado, multa contratual, motorista parado, guincho, e Ã s vezes perda de carga. Na prÃ¡tica, a maioria das frotas ainda funciona no modo reativo: quebrou, conserta. Ou no melhor caso, troca Ã³leo e filtro a cada X km e torce pro resto.

O FleetPred Ã© um sistema de manutenÃ§Ã£o preditiva que usa **IA multi-agente** para diagnosticar problemas em frotas de caminhÃµes pesados operando em mineraÃ§Ã£o. O tÃ©cnico reporta sintomas (vibraÃ§Ã£o, temperatura alta, ruÃ­do), o sistema aciona 5 agentes especializados que consultam dados reais do banco, cruzam com histÃ³rico da frota, e geram um diagnÃ³stico com probabilidade de falha, prazo estimado, plano de aÃ§Ã£o e justificativa financeira.

### Por que esse problema?

Tenho familiaridade com manutenÃ§Ã£o de ativos mÃ³veis e o domÃ­nio de frotas pesadas. ConheÃ§o o dia a dia: tÃ©cnico que descreve problema de um jeito, mecÃ¢nico que interpreta de outro, gestor que precisa decidir qual caminhÃ£o parar primeiro. O sistema multi-agente replica esse fluxo real â€” cada agente Ã© um especialista da equipe.

---

## Arquitetura de LLM

### Fluxo completo

```
TÃ©cnico reporta ocorrÃªncia (sintomas, sistema, severidade)
                    â”‚
                    â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   Orquestrador  â”‚  â† classifica, busca modelo do veÃ­culo
          â”‚   (LangGraph)   â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Diagnosticador â”‚ â”‚   Historiador   â”‚  â† sempre executam
â”‚  (temp 0.2)     â”‚ â”‚   (temp 0.1)    â”‚
â”‚  tool: saÃºde    â”‚ â”‚  tools: histÃ³ricoâ”‚
â”‚  componentes    â”‚ â”‚  + padrÃµes frota â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
         severidade alta/crÃ­tica?
          /                \
        SIM                NÃƒO
         â”‚                  â”‚
         â–¼                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚   Planejador    â”‚         â”‚
â”‚   (temp 0.3)    â”‚         â”‚
â”‚   sem tools     â”‚         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
         â–¼                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚   Financeiro    â”‚         â”‚
â”‚   (temp 0.1)    â”‚         â”‚
â”‚  tool: economia â”‚         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Orquestrador   â”‚  â† consolida tudo num JSON Ãºnico
        â”‚  (consolida)    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â–¼
          JSON padronizado
          â†’ salva no banco
          â†’ exibe no frontend
```

### Por que multi-agente e nÃ£o um LLM sÃ³?

Um prompt Ãºnico com todo o contexto ("diagnostique, analise histÃ³rico, planeje e calcule economia") gera respostas genÃ©ricas. Cada agente tem uma **especialidade e persona diferentes**, como numa equipe real de manutenÃ§Ã£o:

- O **diagnosticador** Ã© um engenheiro de confiabilidade â€” pensa em componentes e modos de falha
- O **historiador** Ã© um analista de dados â€” busca padrÃµes, nÃ£o opina sobre diagnÃ³stico
- O **planejador** Ã© um gestor de manutenÃ§Ã£o â€” equilibra seguranÃ§a com disponibilidade
- O **financeiro** Ã© um analista de custos â€” justifica a intervenÃ§Ã£o com nÃºmeros

Separar em agentes evita que o modelo misture papÃ©is (ex: o historiador diagnosticando ao invÃ©s de analisar dados). Cada agente tem temperatura, tools e restriÃ§Ãµes calibradas pro seu papel.

### Por que LangGraph?

| Alternativa | Problema |
|-------------|----------|
| **API direta** (requests para Gemini) | Funciona para 1 agente, mas nÃ£o orquestra mÃºltiplos agentes com estado compartilhado |
| **LangChain AgentExecutor** | Executa 1 agente com tools, mas nÃ£o tem grafo condicional nem fan-out/fan-in |
| **CrewAI** | Orquestra agentes, mas abstrai demais o fluxo â€” perdi controle sobre quais agentes rodam quando |
| **LangGraph** | Define o fluxo como **grafo explÃ­cito**: nÃ³s = agentes, arestas = condiÃ§Ãµes. O `StateGraph` mantÃ©m estado tipado (`TypedDict`) que cada nÃ³ lÃª e escreve. `add_conditional_edges` implementa a rota por severidade sem if/else manual |

LangGraph foi escolhido porque o fluxo tem **decisÃ£o condicional real**: se a severidade Ã© baixa, nÃ£o faz sentido gastar tokens (e tempo) com planejamento e anÃ¡lise financeira. Isso Ã© uma aresta condicional no grafo, nÃ£o um if/else hardcoded.

### Por que Gemini?

- **Gratuito** na tier free â†’ viÃ¡vel para uso contÃ­nuo pÃ³s-curso, sem custo
- **Tool calling nativo** via `ChatGoogleGenerativeAI` do LangChain
- **gemini-2.0-flash**: rÃ¡pido (~2-5s por chamada), suficiente para o domÃ­nio
- **Context window de 1M tokens**: se no futuro alimentar com manuais tÃ©cnicos inteiros, cabe

**Trade-off reconhecido**: Em produÃ§Ã£o usaria Claude pelo structured output mais robusto (o Gemini Ã s vezes retorna markdown em volta do JSON â€” tive que implementar `_parse_json` com regex como fallback). Mas Gemini gratuito viabiliza uso real e contÃ­nuo sem custo.

---

## System Prompts

Cada agente tem um system prompt em `backend/prompts/`. A decisÃ£o de separar prompts em arquivos `.txt` (e nÃ£o hardcoded no Python) permite iterar no prompt sem reiniciar o servidor e versionar prompts separadamente do cÃ³digo.

### Diagnosticador (`prompts/diagnostician.txt`)

**Persona**: Engenheiro de confiabilidade sÃªnior especializado em frotas pesadas (Scania, Volvo, Mercedes-Benz, DAF) em mineraÃ§Ã£o.

**Por que essa persona**: Ativa o conhecimento do modelo sobre motores DC13, transmissÃµes I-Shift, sistemas pneumÃ¡ticos especÃ­ficos de caminhÃ£o pesado. Uma persona genÃ©rica ("assistente") nÃ£o priorizaria corretamente â€” ex: bronzinas com ruÃ­do em motor diesel pesado Ã© urgÃªncia diferente de um carro de passeio.

**Contexto recebido**: Sistema afetado, sintomas, veÃ­culo ID, km atual. TambÃ©m recebe dados da tool `consultar_saude_componentes`.

**RestriÃ§Ãµes** (delimitadas com XML `<restricoes>`):
- Se probabilidade > 60%, **nunca** recomende "continuar operando" â€” regra de seguranÃ§a inviolÃ¡vel
- Sistemas de seguranÃ§a (freios, direÃ§Ã£o, suspensÃ£o): severidade **mÃ­nima** "alta" â€” nÃ£o importa o que os dados digam, freio com problema nÃ£o Ã© "severidade baixa"
- Se dados insuficientes, recomende inspeÃ§Ã£o presencial â€” evita que o modelo invente dados
- Custos em Reais, realistas pro mercado brasileiro â€” evita alucinaÃ§Ã£o numÃ©rica em USD

**Por que XML tags nas restriÃ§Ãµes**: O `<restricoes>` funciona como delimitador semÃ¢ntico. O modelo trata conteÃºdo dentro de tags XML como regras estruturadas, nÃ£o como texto corrido que pode ser ignorado. Os outros agentes nÃ£o precisam disso porque suas saÃ­das nÃ£o geram risco de seguranÃ§a operacional.

**SaÃ­da**: JSON estrito com 6 campos tipados. Sem texto antes ou depois.

### Historiador (`prompts/historian.txt`)

**Persona**: Analista de dados de frota especializado em identificar padrÃµes de falha.

**Por que essa persona**: Foca o modelo em **anÃ¡lise de dados**, nÃ£o em diagnÃ³stico tÃ©cnico. Sem a persona, ele tentaria diagnosticar ao invÃ©s de buscar padrÃµes. O historiador deve responder "3 caminhÃµes Scania com >200.000 km tiveram o mesmo problema", nÃ£o "o problema Ã© a bomba d'Ã¡gua".

**Contexto recebido**: Sistema, sintomas, veÃ­culo ID. Usa 2 tools para buscar dados.

**Perguntas-guia no prompt** (1. recorrÃªncia, 2. padrÃµes na frota, 3. correlaÃ§Ã£o com km):
Direcionam a anÃ¡lise para informaÃ§Ãµes **acionÃ¡veis** pelo planejador no prÃ³ximo passo. Sem as perguntas, o modelo tende a retornar um resumo narrativo genÃ©rico.

**SaÃ­da**: JSON com `recorrencia` (bool), `intervalo_medio_falha_km` (int|null), `confianca_analise` (enum).

### Planejador (`prompts/planner.txt`)

**Persona**: Gestor de manutenÃ§Ã£o de frota pesada em mineraÃ§Ã£o.

**Por que essa persona**: Um "engenheiro" sempre pararia o caminhÃ£o por seguranÃ§a; um "gestor" pondera custo operacional vs risco. O prompt inclui explicitamente "equilibre seguranÃ§a com disponibilidade" e "cada hora de equipamento parado custa caro" â€” sÃ£o as tensÃµes reais do domÃ­nio.

**Contexto recebido**: DiagnÃ³stico do diagnosticador + anÃ¡lise do historiador (output dos 2 agentes anteriores). NÃ£o tem tools â€” raciocina sobre dados que jÃ¡ existem.

**SaÃ­da**: JSON com `urgencia_horas`, `tipo_manutencao`, `prioridade`, `tempo_reparo_horas`, `justificativa`.

### Financeiro (`prompts/financial.txt`)

**Persona**: Analista de custos de manutenÃ§Ã£o de frota.

**Por que essa persona**: Foco em ROI e justificativa financeira. O prompt inclui referÃªncias de custo reais do mercado brasileiro de mineraÃ§Ã£o (hora parada ~R$ 800-1.200, guincho ~R$ 3.000-8.000) para **ancorar** o modelo em valores realistas e evitar alucinaÃ§Ã£o numÃ©rica.

**Contexto recebido**: Sistema, componente identificado pelo diagnosticador, modelo do veÃ­culo. Usa a tool `calcular_economia` para obter dados reais de custo.

**SaÃ­da**: JSON com `economia_estimada`, `roi_preditiva`, `pecas_sugeridas` (com custos).

### Orquestrador (`prompts/orchestrator.txt`)

**Persona**: Coordenador de diagnÃ³stico de frota pesada em mineraÃ§Ã£o.

**Por que essa persona**: NÃ£o diagnostica â€” **consolida**. Recebe as saÃ­das de todos os agentes e monta o JSON final padronizado. O prompt termina com "Responda APENAS com o JSON final, sem texto antes ou depois" â€” instruÃ§Ã£o crÃ­tica porque o orquestrador Ã© o Ãºltimo passo antes do banco de dados.

**Regra de roteamento no prompt**: "SEMPRE acione Diagnosticador e Historiador; se severidade alta/crÃ­tica acione Planejador e Financeiro". Essa regra estÃ¡ tanto no prompt quanto implementada como `add_conditional_edges` no grafo â€” defesa em profundidade.

### Por que JSON estrito em todos os agentes

- O frontend faz `JSON.parse()` da resposta â€” qualquer texto fora do JSON quebra o parsing
- Agentes intermediÃ¡rios consomem a saÃ­da do anterior programaticamente
- JSON estruturado permite logs queryÃ¡veis e detecÃ§Ã£o de drift na qualidade
- Sem a instruÃ§Ã£o explÃ­cita "APENAS JSON", o Gemini adiciona "Claro! Aqui estÃ¡ o diagnÃ³stico..." antes do JSON

### Por que nÃ£o usar few-shot

Em sistemas de prompt Ãºnico, few-shot Ã© essencial para alinhar formato. Aqui nÃ£o Ã© necessÃ¡rio porque:

1. **O contexto vem das tools, nÃ£o do prompt** â€” os agentes recebem dados reais do banco, nÃ£o exemplos fabricados
2. **Os agentes se complementam** â€” a saÃ­da do diagnosticador funciona como "few-shot" para o planejador
3. **JSON schema no prompt jÃ¡ define o formato** â€” especificar o schema exato Ã© mais eficaz que mostrar um exemplo
4. **Risco de viÃ©s** â€” few-shot com dados de mineraÃ§Ã£o poderia enviesar o modelo para sempre diagnosticar os mesmos problemas do exemplo

---

## Ferramentas (Tools)

4 ferramentas implementadas em `backend/tools/fleet_tools.py`, expostas aos agentes via `@tool` decorator do LangChain em cada arquivo de agente.

### Por que 4 tools e nÃ£o mais (nem menos)

- **Menos de 4**: O LLM teria que **inventar** dados que poderia consultar. Sem `consultar_saude_componentes`, estimaria a saÃºde baseado sÃ³ nos sintomas (viÃ©s de confirmaÃ§Ã£o).
- **Mais de 4**: Aumenta a probabilidade de **tool confusion** â€” o modelo escolhe a ferramenta errada ou tenta chamar mÃºltiplas quando uma bastava.
- Cada ferramenta mapeia para uma **fonte de dados distinta** no banco. Nenhuma sobrepÃµe a outra.

**PrincÃ­pio**: Toda informaÃ§Ã£o que existe no banco deve vir de uma tool, nÃ£o da "memÃ³ria" do modelo. O modelo Ã© bom em raciocÃ­nio, nÃ£o em recall de dados especÃ­ficos.

### `consultar_saude_componentes`

| | |
|---|---|
| **Usada por** | Diagnosticador |
| **O que faz** | Retorna saÃºde percentual (0-100%) de cada componente de um veÃ­culo |
| **ParÃ¢metros** | `veiculo_id: int` |
| **Por que o LLM precisa** | Sem ela, estimaria saÃºde baseado sÃ³ nos sintomas. Com ela, vÃª o estado **real medido** â€” pode atÃ© contradizer os sintomas (ex: tÃ©cnico reporta vibraÃ§Ã£o, mas a saÃºde da suspensÃ£o estÃ¡ em 92%) |
| **Fonte no banco** | Tabela `componentes` |

### `consultar_historico_veiculo`

| | |
|---|---|
| **Usada por** | Historiador |
| **O que faz** | Busca as Ãºltimas N manutenÃ§Ãµes de um veÃ­culo especÃ­fico (tipo, descriÃ§Ã£o, data, custo, peÃ§as) |
| **ParÃ¢metros** | `veiculo_id: int`, `limite: int = 10` |
| **Por que o LLM precisa** | Sem ela, inventaria um histÃ³rico plausÃ­vel mas **falso**. Com ela, acessa manutenÃ§Ãµes reais com datas e custos reais â€” pode identificar recorrÃªncia |
| **Fonte no banco** | Tabelas `veiculos` + `manutencoes` |

### `buscar_padroes_frota`

| | |
|---|---|
| **Usada por** | Historiador |
| **O que faz** | Busca ocorrÃªncias de **outros veÃ­culos** com mesmo sistema e sintomas parecidos, incluindo diagnÃ³stico e resultado |
| **ParÃ¢metros** | `sistema: str`, `sintomas: list[str]` |
| **Por que o LLM precisa** | Sem ela, nÃ£o saberia que 3 outros Scania tiveram o mesmo problema. Com ela, encontra padrÃµes reais na frota e correlaciona |
| **Fonte no banco** | Tabelas `ocorrencias` + `veiculos` + `diagnosticos` |

### `calcular_economia`

| | |
|---|---|
| **Usada por** | Financeiro |
| **O que faz** | Calcula economia estimada: preventiva vs corretiva. Usa dados reais do banco quando disponÃ­veis (>= 2 registros), senÃ£o usa estimativas calibradas do mercado brasileiro |
| **ParÃ¢metros** | `sistema: str`, `componente: str`, `modelo_veiculo: str` |
| **Por que o LLM precisa** | Sem ela, **chutaria valores** de custo (alucinaÃ§Ã£o numÃ©rica clÃ¡ssica). Com ela, calcula baseado em dados reais ou estimativas calibradas |
| **Fonte no banco** | Tabela `manutencoes` (agregaÃ§Ãµes) + fallback com estimativas de mercado |

### Por que `consultar_historico` e `buscar_padroes` sÃ£o separadas

Poderiam ser uma tool sÃ³? NÃ£o:

1. **Escopo diferente**: histÃ³rico Ã© de **um** veÃ­culo (vertical, profundo); padrÃµes Ã© de **toda a frota** (horizontal, amplo)
2. **Performance**: histÃ³rico Ã© O(1) no Ã­ndice; padrÃµes faz scan + comparaÃ§Ã£o de sintomas â€” mais custoso
3. **Granularidade**: o agente pode chamar sÃ³ o que precisa. Em produÃ§Ã£o, `buscar_padroes` pode precisar de cache; `consultar_historico` nÃ£o

### Por que descriptions incluem "quando usar"

```
"Usar quando precisar entender o histÃ³rico de manutenÃ§Ã£o de um veÃ­culo
para identificar padrÃµes de falha recorrentes ou avaliar o estado geral."
```

O modelo decide **qual tool chamar** baseado na description. Se diz apenas "busca manutenÃ§Ãµes", o modelo pode nÃ£o perceber que Ã© a ferramenta certa para "verificar se o problema Ã© recorrente". O "quando usar" dÃ¡ um **critÃ©rio de acionamento**, nÃ£o apenas uma capacidade.

### PadrÃ£o de tool execution

Todos os agentes usam um loop manual (nÃ£o usa `AgentExecutor` do LangChain):

```python
response = llm_with_tools.invoke(messages)
while response.tool_calls:
    messages.append(response)
    for tc in response.tool_calls:
        result = tools_map[tc["name"]].invoke(tc["args"])
        messages.append(ToolMessage(content=str(result), tool_call_id=tc["id"]))
    response = llm_with_tools.invoke(messages)
```

**Por que loop manual e nÃ£o AgentExecutor**: Mais controle, menos abstraÃ§Ã£o. Sei exatamente quantas vezes o LLM chamou tools, posso logar cada chamada, e evito comportamentos inesperados do AgentExecutor (como loops infinitos se o modelo fica preso).

---

## ParÃ¢metros do Modelo

| Agente | Modelo | Temperatura | Justificativa |
|--------|--------|-------------|---------------|
| Diagnosticador | gemini-2.0-flash | 0.2 | DiagnÃ³stico tÃ©cnico precisa ser determinÃ­stico. Mesmos sintomas â†’ mesmo diagnÃ³stico. |
| Historiador | gemini-2.0-flash | 0.1 | Consulta dados factuais. NÃ£o pode "inventar" padrÃµes que nÃ£o existem no banco. |
| Planejador | gemini-2.0-flash | 0.3 | Precisa ponderar trade-offs entre urgÃªncia e disponibilidade. Mais flexÃ­vel. |
| Financeiro | gemini-2.0-flash | 0.1 | NÃºmeros devem ser exatos. CÃ¡lculos financeiros sÃ£o determinÃ­sticos. |
| Orquestrador (consolida) | gemini-2.0-flash | 0.1 | ConsolidaÃ§Ã£o final â€” deve ser fiel Ã s saÃ­das dos agentes, nÃ£o criativo. |

### Por que temperatura baixa em geral

DiagnÃ³stico de manutenÃ§Ã£o **nÃ£o Ã© tarefa criativa**. Se um tÃ©cnico reporta "ruÃ­do anormal no motor" a 245.000 km, a resposta correta Ã© bronzinas/bielas, nÃ£o uma resposta criativa diferente a cada vez. Temperatura alta geraria variaÃ§Ã£o indesejada: mesmos sintomas, diagnÃ³sticos diferentes â†’ perda de confianÃ§a do operador.

### Por que o Planejador tem a mais alta (0.3)

O planejador Ã© o Ãºnico agente que faz **julgamento subjetivo**: "paro o caminhÃ£o agora e perco produÃ§Ã£o, ou arrisco mais 2 dias?". Precisa de flexibilidade para ponderar trade-offs que nÃ£o tÃªm resposta Ãºnica. Mesmo assim, 0.3 Ã© conservador â€” o suficiente para variar a justificativa sem inventar dados.

### Por que gemini-2.0-flash e nÃ£o gemini-pro

- **Flash Ã© gratuito** na tier free com limites generosos
- **Mais rÃ¡pido** (~2-5s vs ~8-15s por chamada) â€” importa porque sÃ£o 3-6 chamadas LLM por diagnÃ³stico
- **Suficiente pro caso** â€” o raciocÃ­nio necessÃ¡rio aqui Ã© "correlacionar sintomas com componentes" e "seguir instruÃ§Ãµes do prompt", nÃ£o raciocÃ­nio de mÃºltiplas etapas complexo
- Em testes, a qualidade do diagnÃ³stico com flash vs pro foi equivalente para este domÃ­nio

---

## ResiliÃªncia: Fallback e Parsing

### Fallback para mock

Se **qualquer** exceÃ§Ã£o ocorrer no pipeline LLM (API fora, quota excedida, timeout, parsing falho), o sistema cai para o `mock_ai.generate_mock_diagnostic()` â€” que retorna diagnÃ³stico baseado em mapeamento estÃ¡tico por sistema/sintoma. O sistema **nunca quebra** para o usuÃ¡rio.

```python
# Em orchestrator.py
except Exception as e:
    print(f"[Orchestrator] ERRO apÃ³s {elapsed:.1f}s: {e}")
    return generate_mock_diagnostic(sistema=sistema, sintomas=sintomas, veiculo_km=km)
```

```python
# Em routes/ocorrencias.py â€” segunda camada de fallback
try:
    diag = orchestrate(...)
except Exception as e:
    diag = generate_mock_diagnostic(...)
```

Duas camadas de fallback: uma dentro do orchestrator (pega erros dos agentes/LLM), outra na rota (pega erros de import ou inicializaÃ§Ã£o).

### Parsing robusto de JSON

O Gemini Ã s vezes retorna JSON dentro de blocos markdown (`` ```json ... ``` ``). Todos os agentes usam `_parse_json()`:

```python
def _parse_json(text: str) -> dict:
    try:
        return json.loads(text)              # tenta direto
    except json.JSONDecodeError:
        match = re.search(r"\{.*\}", text, re.DOTALL)  # busca {...} no texto
        if match:
            try:
                return json.loads(match.group())
            except json.JSONDecodeError:
                pass
        return {}                            # fallback seguro: dict vazio
```

3 camadas: parse direto â†’ regex para extrair JSON â†’ dict vazio. O dict vazio Ã© seguro porque o orchestrator usa `.get()` com defaults para todos os campos.

---

## O que Funcionou

### SeparaÃ§Ã£o de responsabilidades por agente

Quando tudo estava num prompt sÃ³, o Gemini misturava diagnÃ³stico com planejamento â€” sugeria "trocar bomba d'Ã¡gua em 48 horas" sem antes confirmar que era a bomba d'Ã¡gua. Com agentes separados, o diagnosticador **primeiro confirma** o componente (consultando saÃºde real), e sÃ³ depois o planejador define prazo.

### RestriÃ§Ãµes com XML tags no diagnosticador

A tag `<restricoes>` no prompt do diagnosticador fez diferenÃ§a mensurÃ¡vel. Sem ela, o modelo Ã s vezes sugeria "monitorar" para freios com probabilidade de falha de 70%. Com a tag, a regra "sistemas de seguranÃ§a = severidade mÃ­nima alta" Ã© respeitada consistentemente.

### Fallback duplo

Testado intencionalmente desligando a internet: o orchestrator pega a exceÃ§Ã£o de rede, imprime o log de erro, e retorna o mock em <1ms. O usuÃ¡rio recebe diagnÃ³stico (menos preciso, mas funcional). TambÃ©m testado com quota excedida (429) â€” mesmo comportamento.

### Tools com descriptions contextuais

Adicionar "Usar quando precisar..." nas descriptions das tools reduziu chamadas desnecessÃ¡rias. Sem essa frase, o diagnosticador Ã s vezes chamava `consultar_saude_componentes` e depois tentava chamar o histÃ³rico (que nÃ£o Ã© tool dele). Com a description contextualizada, cada agente chama apenas suas tools.

### Timing em cada agente

Cada agente imprime `[NomeAgente] concluÃ­do em X.Xs`. Permite identificar gargalos rapidamente. O diagnosticador com tool calling Ã© o mais lento (~3-5s); o planejador sem tools Ã© o mais rÃ¡pido (~1-2s).

---

## O que NÃ£o Funcionou

### Gemini e markdown no JSON

O Gemini 2.0 Flash frequentemente retorna JSON dentro de blocos markdown (`` ```json\n{...}\n``` ``), mesmo com instruÃ§Ã£o explÃ­cita "APENAS JSON". Tentei variaÃ§Ãµes do prompt:
- "Retorne apenas JSON" â†’ ~70% sem markdown
- "Responda APENAS com o JSON, sem texto antes ou depois" â†’ ~85% sem markdown
- Regex `_parse_json()` como fallback â†’ 100% de sucesso no parsing

O Claude seria mais robusto aqui com structured output nativo, mas o regex resolve.

### Tool calling do Gemini vs Claude

O Gemini Ã s vezes inventa nomes de tools que nÃ£o existem no `bind_tools()`, ou passa parÃ¢metros com tipo errado (string onde deveria ser int). Simplificar as descriptions e manter poucos parÃ¢metros por tool (1-3) reduziu significativamente esse problema. Com descriptions longas e detalhadas, a taxa de erro subia.

### Temperatura 0.0 quebra o financeiro

Com temperatura 0.0, o financeiro ficava preso em loops: chamava `calcular_economia` â†’ recebia resultado â†’ chamava de novo com os mesmos parÃ¢metros. Subir para 0.1 resolveu â€” aparentemente o Gemini precisa de alguma variÃ¢ncia para sair do loop de tool calling.

### Primeiro prompt do orquestrador era longo demais

O prompt original do orquestrador tinha exemplos de cada tipo de diagnÃ³stico (~2000 tokens). Cortei para ~600 tokens focando nas **regras de roteamento** e no **schema do JSON final**. O resultado melhorou â€” o modelo seguia o schema com mais consistÃªncia quando tinha menos informaÃ§Ã£o competindo por atenÃ§Ã£o.

---

## Uso do Agente de CodificaÃ§Ã£o

**Ferramenta:** Claude Code (CLI)

**Processo da versÃ£o final:**

1. **Planejamento**: defini a arquitetura multi-agente, quais tools cada agente precisa, e o fluxo do grafo antes de pedir cÃ³digo
2. **Prompts primeiro**: escrevi os system prompts e DECISOES.md antes de implementar os agentes â€” a engenharia de prompt guiou o cÃ³digo, nÃ£o o contrÃ¡rio
3. **ImplementaÃ§Ã£o incremental**: llm_config â†’ agentes individuais â†’ orchestrator â†’ integraÃ§Ã£o na rota
4. **Teste end-to-end**: POST real na API pra validar o fluxo completo incluindo fallback

**ProporÃ§Ã£o versÃ£o final:**
- Planejamento e prompts: ~30% do tempo
- Gerado pelo agente: ~50%
- RevisÃ£o e ajuste: ~20%

---

## Como Executar

**PrÃ©-requisitos:** Python 3.10+ e Node.js 18+

```bash
git clone https://github.com/RoseBorges44/fleetpred.git
cd fleetpred

# 1. Configurar chave da API
cp backend/.env.example backend/.env
# Edite backend/.env e cole sua GEMINI_API_KEY

# 2. Backend
cd backend
pip install -r requirements.txt
uvicorn main:app --reload --port 8000

# 3. Frontend (outro terminal)
cd frontend
npm install
npm run dev
```

**Acessar:** http://localhost:5173 (frontend) Â· http://localhost:8000/docs (API)

**Sem chave Gemini?** O sistema funciona normalmente â€” usa o fallback mock_ai automaticamente.

---

## Estrutura do Projeto

```
fleetpred/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                  # App FastAPI, CORS, registro de rotas
â”‚   â”œâ”€â”€ database.py              # Schema SQLite â€” 6 tabelas
â”‚   â”œâ”€â”€ seed_data.py             # 10 caminhÃµes com dados realistas
â”‚   â”œâ”€â”€ mock_ai.py               # DiagnÃ³stico mock â€” mantido como fallback
â”‚   â”œâ”€â”€ .env                     # GEMINI_API_KEY (nÃ£o versionado)
â”‚   â”œâ”€â”€ .env.example             # Template da .env
â”‚   â”œâ”€â”€ requirements.txt         # DependÃªncias (LangGraph, LangChain, Gemini, etc.)
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/                  # Sistema multi-agente
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ llm_config.py        # get_llm(), load_prompt() â€” config centralizada
â”‚   â”‚   â”œâ”€â”€ orchestrator.py      # LangGraph StateGraph â€” orquestra o fluxo
â”‚   â”‚   â”œâ”€â”€ diagnostician.py     # Agente diagnosticador (temp 0.2, 1 tool)
â”‚   â”‚   â”œâ”€â”€ historian.py         # Agente historiador (temp 0.1, 2 tools)
â”‚   â”‚   â”œâ”€â”€ planner.py           # Agente planejador (temp 0.3, sem tools)
â”‚   â”‚   â””â”€â”€ financial.py         # Agente financeiro (temp 0.1, 1 tool)
â”‚   â”‚
â”‚   â”œâ”€â”€ prompts/                 # System prompts dos agentes
â”‚   â”‚   â”œâ”€â”€ orchestrator.txt     # Coordenador â€” consolida JSON final
â”‚   â”‚   â”œâ”€â”€ diagnostician.txt    # Engenheiro de confiabilidade
â”‚   â”‚   â”œâ”€â”€ historian.txt        # Analista de dados de frota
â”‚   â”‚   â”œâ”€â”€ planner.txt          # Gestor de manutenÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ financial.txt        # Analista de custos
â”‚   â”‚   â””â”€â”€ DECISOES.md          # Justificativas de design dos prompts
â”‚   â”‚
â”‚   â”œâ”€â”€ tools/                   # Ferramentas dos agentes
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ fleet_tools.py       # 4 tools: saÃºde, histÃ³rico, padrÃµes, economia
â”‚   â”‚   â””â”€â”€ DECISOES.md          # Justificativas de design das tools
â”‚   â”‚
â”‚   â””â”€â”€ routes/
â”‚       â”œâ”€â”€ veiculos.py          # Dashboard stats, lista, detalhe
â”‚       â”œâ”€â”€ ocorrencias.py       # Registro + chamada ao orchestrator + fallback
â”‚       â”œâ”€â”€ manutencoes.py       # Agendadas + fila de prioridade
â”‚       â”œâ”€â”€ relatorios.py        # Custos, disponibilidade, tendÃªncia
â”‚       â””â”€â”€ alertas.py           # Alertas + diagnÃ³stico detalhado
â”‚
â”œâ”€â”€ frontend/                    # React + Vite (nÃ£o alterado na versÃ£o final)
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ App.jsx
â”‚       â”œâ”€â”€ index.css
â”‚       â”œâ”€â”€ services/api.js
â”‚       â””â”€â”€ pages/               # 6 telas da aplicaÃ§Ã£o
â”‚
â”œâ”€â”€ start.sh
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```
