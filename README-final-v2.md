# ğŸš› FleetPred â€” ManutenÃ§Ã£o Preditiva de Frota com IA Multi-Agente

> AvaliaÃ§Ã£o Final Â· IA Generativa Â· UniSENAI  
> Rosemeri Janiski Bida de Oliveira Borges

**RepositÃ³rio:** https://github.com/RoseBorges44/fleetpred  
**Endpoint:** [COLAR LINK NGROK OU RAILWAY]

---

## O Problema

Quem trabalha com manutenÃ§Ã£o de frota pesada em mineraÃ§Ã£o sabe: manutenÃ§Ã£o corretiva Ã© o pesadelo da operaÃ§Ã£o. Um caminhÃ£o fora de estrada que para no meio do ciclo de carregamento nÃ£o Ã© sÃ³ o custo do reparo â€” Ã© produÃ§Ã£o parada, fila na mina, replanejamento de despacho e guincho de equipamento pesado.

JÃ¡ vi caminhÃ£o parar na rampa de acesso por desgaste de componente que a anÃ¡lise de Ã³leo tinha apontado semanas antes â€” excesso de ferro indicando desgaste interno no motor, e ninguÃ©m cruzou a informaÃ§Ã£o a tempo. O custo da corretiva foi umas 4x o que teria sido uma preventiva programada.

O FleetPred resolve isso com IA generativa: o tÃ©cnico reporta sintomas, um sistema multi-agente analisa o problema de 4 Ã¢ngulos diferentes (diagnÃ³stico tÃ©cnico, histÃ³rico, planejamento e financeiro), e entrega uma recomendaÃ§Ã£o estruturada com probabilidade de falha, prazo e ROI.

---

## Arquitetura de LLM

### Fluxo completo

```
TÃ©cnico reporta ocorrÃªncia (via formulÃ¡rio web)
        â†“
   POST /api/ocorrencias/
        â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚    ORQUESTRADOR      â”‚  â† Avalia severidade, decide quais agentes chamar
  â”‚  (LangGraph + Gemini)â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  ExecuÃ§Ã£o paralela:          â”‚
  â”‚                              â”‚
  â”‚  [DIAGNOSTICADOR]            â”‚  â† Analisa sintomas + saÃºde componentes
  â”‚    tool: consultar_saude     â”‚
  â”‚    temp: 0.2                 â”‚
  â”‚                              â”‚
  â”‚  [HISTORIADOR]               â”‚  â† Busca padrÃµes na frota e histÃ³rico
  â”‚    tools: historico, padroes â”‚
  â”‚    temp: 0.1                 â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
       Severidade alta/crÃ­tica?
          â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
         SIM           NÃƒO
          â†“              â†“
  [PLANEJADOR]     [CONSOLIDAR]
    temp: 0.3           â†“
       â†“           JSON final
  [FINANCEIRO]
    tool: calcular_economia
    temp: 0.1
       â†“
  [CONSOLIDAR]
       â†“
  JSON final â†’ Salva no banco â†’ Cria alerta â†’ Retorna pro frontend
```

### Por que multi-agente e nÃ£o um LLM sÃ³

Na manutenÃ§Ã£o real de mineraÃ§Ã£o, o diagnÃ³stico nÃ£o Ã© feito por uma pessoa. Ã‰ um fluxo entre especialistas: o tÃ©cnico de campo reporta, o analista de dados cruza com histÃ³rico, o planejador decide prioridade, o financeiro justifica o custo. Cada um olha o mesmo problema de um Ã¢ngulo diferente.

Um prompt Ãºnico com "analise isso tudo" gera respostas genÃ©ricas. Separar em agentes permite:
- Cada agente ter persona e restriÃ§Ãµes especÃ­ficas
- O historiador buscar dados reais do banco (via tools) antes do diagnosticador opinar
- Executar diagnosticador e historiador em paralelo (menor latÃªncia)
- Acionar planejador e financeiro apenas quando necessÃ¡rio (economia de tokens)
- Isolar falhas â€” se o financeiro der erro, o diagnÃ³stico tÃ©cnico ainda funciona

### Por que LangGraph

| Framework | Problema |
|---|---|
| **API direta** | Funciona pra 1 agente, mas nÃ£o tem orquestraÃ§Ã£o de mÃºltiplos agentes com estado compartilhado |
| **LangChain** | Bom pra chains lineares, mas nÃ£o tem grafo condicional (bifurcar por severidade) |
| **CrewAI** | Mais alto nÃ­vel mas menos controle sobre o fluxo e estado |
| **LangGraph** âœ… | Grafo com nÃ³s condicionais, execuÃ§Ã£o paralela, estado tipado, fallback por nÃ³ |

LangGraph permite definir o fluxo como grafo â€” o orquestrador decide quais agentes chamar dependendo da severidade. Caso crÃ­tico aciona todos. Caso leve pula planejador e financeiro.

### Por que Gemini

| CritÃ©rio | Gemini | Claude | GPT |
|---|---|---|---|
| Custo | Gratuito (free tier) | Pago | Pago |
| Tool calling | âœ… Nativo | âœ… Robusto | âœ… Robusto |
| Context window | 1M tokens | 200K | 128K |
| Velocidade | RÃ¡pido (flash) | MÃ©dio | MÃ©dio |
| Uso pÃ³s-curso | âœ… Sem custo | âŒ Precisa pagar | âŒ Precisa pagar |

**Trade-off honesto:** Claude tem structured output mais robusto e o tool calling Ã© mais preciso. Em produÃ§Ã£o, provavelmente migraria pra Claude. Mas Gemini gratuito viabiliza uso contÃ­nuo sem custo â€” o que o professor pediu (algo que usemos depois do curso acabar). Com o context window de 1M tokens, cabe o histÃ³rico inteiro da frota sem precisar de RAG.

---

## System Prompts

Cada agente tem seu prÃ³prio system prompt em `prompts/`. A separaÃ§Ã£o Ã© proposital â€” prompts diferentes permitem persona, restriÃ§Ãµes e formato diferentes por especialidade.

### Orquestrador (`prompts/orchestrator.txt`)

**Persona:** Coordenador de diagnÃ³stico de frota em mineraÃ§Ã£o.  
**FunÃ§Ã£o:** Recebe a ocorrÃªncia, decide quais agentes acionar com base na severidade, e consolida o resultado final num JSON Ãºnico.  
**Por que existe:** Sem orquestrador, os agentes nÃ£o sabem em que ordem rodar nem quando parar. O orquestrador implementa a lÃ³gica de negÃ³cio: severidade alta/crÃ­tica aciona todos os agentes, severidade baixa pula planejador e financeiro.  
**Formato de saÃ­da:** JSON estrito com os campos que o frontend espera (componente, probabilidade_falha, horizonte_dias, etc.). A instruÃ§Ã£o "APENAS com o JSON final, sem texto antes ou depois" existe porque sem ela o modelo Ã s vezes coloca explicaÃ§Ãµes antes do JSON e o `json.loads()` quebra.

### Diagnosticador (`prompts/diagnostician.txt`)

**Persona:** Engenheiro de confiabilidade sÃªnior, 15 anos de experiÃªncia em frotas pesadas em mineraÃ§Ã£o.  
**FunÃ§Ã£o:** Analisa os sintomas no contexto tÃ©cnico do veÃ­culo (modelo, motor, km, saÃºde dos componentes).  
**RestriÃ§Ãµes crÃ­ticas (XML tags):**
- Se probabilidade > 60%, nunca recomende "continuar operando" â†’ veÃ­culo com 60%+ de chance de falhar nÃ£o pode rodar em rampa de mina
- Sistemas de seguranÃ§a (freios, direÃ§Ã£o, suspensÃ£o): severidade mÃ­nima "alta" â†’ em mineraÃ§Ã£o, falha de freio em rampa Ã© fatal
- Dados insuficientes â†’ recomende inspeÃ§Ã£o presencial (melhor ser conservador)

**Por que XML tags nas restriÃ§Ãµes:** Claude e Gemini processam melhor instruÃ§Ãµes quando a estrutura Ã© explÃ­cita. Testei sem tags e o modelo misturava dados do veÃ­culo com instruÃ§Ãµes de formato. Com `<restricoes>...</restricoes>` cada bloco fica isolado.

### Historiador (`prompts/historian.txt`)

**Persona:** Analista de dados de frota.  
**FunÃ§Ã£o:** Busca no banco de dados o histÃ³rico deste veÃ­culo e padrÃµes em veÃ­culos similares.  
**Por que Ã© um agente separado:** O diagnosticador nÃ£o sabe o que aconteceu com outros caminhÃµes da frota. Se 3 Scanias DC13 falharam o turbo entre 300-350 mil km, essa informaÃ§Ã£o Ã© ouro pro diagnÃ³stico. O historiador busca esses padrÃµes via tools e alimenta o orquestrador.

### Planejador (`prompts/planner.txt`)

**Persona:** Gestor de manutenÃ§Ã£o de frota em mineraÃ§Ã£o.  
**FunÃ§Ã£o:** Define urgÃªncia (horas/dias), tipo de manutenÃ§Ã£o, prioridade na fila e tempo estimado de reparo.  
**Por que temperatura 0.3 (a mais alta):** Planejamento envolve ponderar trade-offs â€” "paro agora e perco 4h de produÃ§Ã£o, ou arrisco mais 3 dias e faÃ§o no fim de semana?". Precisa de flexibilidade na formulaÃ§Ã£o, diferente do diagnÃ³stico tÃ©cnico que Ã© mais objetivo.

### Financeiro (`prompts/financial.txt`)

**Persona:** Analista de custos de manutenÃ§Ã£o.  
**FunÃ§Ã£o:** Calcula ROI de agir preventivamente. Em mineraÃ§Ã£o, inclui custo de hora de caminhÃ£o parado (~R$ 800-1.200/h), guincho (~R$ 3.000-8.000), replanejamento de despacho.  
**Por que existe:** Gestor de frota em mineraÃ§Ã£o decide com base em custo. "Troque a vÃ¡lvula" Ã© recomendaÃ§Ã£o tÃ©cnica. "Troque agora por R$ 2.400 ou arrisque R$ 12.000 de corretiva na mina" Ã© recomendaÃ§Ã£o de negÃ³cio.

---

## Ferramentas (Tools)

Definidas em `tools/tool_definitions.json` e implementadas em `backend/tools/fleet_tools.py`.

### 1. `consultar_saude_componentes(veiculo_id)`

**O que faz:** Retorna saÃºde (0-100%) de cada componente do veÃ­culo.  
**Por que o LLM precisa:** Sem essa tool, o modelo nÃ£o sabe que o sistema de arrefecimento do ABC-1234 estÃ¡ em 58%. O mesmo sintoma num componente com 90% de saÃºde vs 45% muda completamente o diagnÃ³stico.  
**Quem usa:** Diagnosticador.

### 2. `consultar_historico_veiculo(veiculo_id, limite)`

**O que faz:** Busca Ãºltimas N manutenÃ§Ãµes do veÃ­culo (tipo, data, custo, peÃ§as).  
**Por que o LLM precisa:** Um veÃ­culo que jÃ¡ trocou turbo 2 vezes pode indicar problema na causa raiz, nÃ£o no componente. Sem histÃ³rico, diagnÃ³stico Ã© genÃ©rico.  
**Quem usa:** Historiador.

### 3. `buscar_padroes_frota(sistema, sintomas)`

**O que faz:** Busca ocorrÃªncias de outros veÃ­culos com mesmo sistema e sintomas semelhantes.  
**Por que o LLM precisa:** Essa tool transforma o sistema de "chatbot de manutenÃ§Ã£o" em "preditivo de verdade". Se 3 veÃ­culos similares falharam com os mesmos sintomas, a probabilidade de falha sobe.  
**Quem usa:** Historiador.  
**Por que separada de consultar_historico:** Uma olha o veÃ­culo especÃ­fico, outra olha a frota toda. Nem sempre precisa das duas.

### 4. `calcular_economia(sistema, componente, modelo_veiculo)`

**O que faz:** Compara custo de preventiva agora vs. corretiva eventual (incluindo guincho, produÃ§Ã£o parada).  
**Por que Ã© uma tool e nÃ£o hardcoded:** Custos variam por modelo, componente e regiÃ£o. A tool consulta dados reais do banco quando disponÃ­veis e usa estimativas de mercado como fallback.  
**Quem usa:** Financeiro.

### Por que as descriptions incluem "quando usar"

Testei com descriptions genÃ©ricas ("busca dados do veÃ­culo") e o modelo chamava todas as tools em sequÃªncia, sempre. Com descriptions que dizem quando usar ("Use para embasar o diagnÃ³stico com dados reais da frota"), o modelo passou a ser seletivo â€” sÃ³ chama quando relevante.

---

## ParÃ¢metros do Modelo

| Agente | Modelo | Temperatura | Por quÃª |
|---|---|---|---|
| Diagnosticador | gemini-2.0-flash | 0.2 | DiagnÃ³stico tÃ©cnico precisa de consistÃªncia. Mesmos sintomas â†’ mesmo diagnÃ³stico. |
| Historiador | gemini-2.0-flash | 0.1 | Consulta e interpreta dados. Deve ser o mais determinÃ­stico possÃ­vel. |
| Planejador | gemini-2.0-flash | 0.3 | Precisa ponderar trade-offs (seguranÃ§a vs. disponibilidade). Um pouco mais de flexibilidade. |
| Financeiro | gemini-2.0-flash | 0.1 | NÃºmeros precisam ser consistentes. R$ 5.800 nÃ£o pode virar R$ 12.000 na prÃ³xima chamada. |
| Orquestrador | gemini-2.0-flash | 0.2 | Coordena fluxo e consolida. Precisa de consistÃªncia no formato JSON. |

**Por que temperatura baixa em geral:** DiagnÃ³stico de manutenÃ§Ã£o nÃ£o Ã© criativo. Se o tÃ©cnico reporta os mesmos sintomas duas vezes, o sistema precisa dar o mesmo diagnÃ³stico (ou muito parecido). Temperatura alta (0.7+) fazia o modelo variar a probabilidade entre 65% e 88% pro mesmo caso â€” inaceitÃ¡vel pra um sistema de decisÃ£o.

**Por que gemini-2.0-flash:** Ã‰ o modelo gratuito mais rÃ¡pido. O multi-agente faz 3-5 chamadas por diagnÃ³stico â€” latÃªncia importa. O modelo "pro" Ã© mais preciso mas pago e mais lento. Para o caso de uso (diagnÃ³stico estruturado com tools), flash Ã© suficiente.

**O que testei:**
- Temperatura 0: totalmente determinÃ­stico, mas recomendaÃ§Ãµes ficavam robotizadas ("Substituir componente X. Agendar para data Y.")
- Temperatura 0.2: consistÃªncia nos nÃºmeros, leve variaÃ§Ã£o na redaÃ§Ã£o
- Temperatura 0.7: probabilidades variavam demais entre chamadas idÃªnticas

---

## Escolha de Framework

### Por que LangGraph e nÃ£o alternativas

**API direta (google-generativeai):** Funciona pra um agente. Pra multi-agente, eu teria que implementar manualmente: orquestraÃ§Ã£o, passagem de contexto entre agentes, execuÃ§Ã£o condicional, tratamento de erro por agente. LangGraph jÃ¡ tem tudo isso.

**LangChain sozinho:** Bom pra chains lineares (entrada â†’ processamento â†’ saÃ­da). Mas meu fluxo tem bifurcaÃ§Ã£o condicional (severidade alta aciona mais agentes) e execuÃ§Ã£o paralela (diagnosticador e historiador rodam ao mesmo tempo). LangChain nÃ£o tem grafo nativo.

**CrewAI:** Mais alto nÃ­vel, menos cÃ³digo. Mas menos controle sobre o fluxo e o estado compartilhado entre agentes. Em LangGraph, eu defino exatamente quais dados cada nÃ³ recebe e passa adiante.

**LangGraph:** Grafo com nÃ³s tipados, edges condicionais, execuÃ§Ã£o paralela nativa, e StateGraph que mantÃ©m o estado entre agentes. Cada agente Ã© um nÃ³, cada transiÃ§Ã£o Ã© um edge, e a condiÃ§Ã£o de bifurcaÃ§Ã£o Ã© uma funÃ§Ã£o Python pura.

---

## Fallback e Tratamento de Erros

O sistema tem fallback em cascata:

1. Orquestrador tenta chamar os agentes com Gemini
2. Se Gemini falhar (timeout, quota, erro de parsing), cai pro `mock_ai.py` original
3. O mock retorna diagnÃ³stico estÃ¡tico (mesma estrutura JSON) â€” sistema nunca quebra

```python
try:
    diagnostic = orchestrate(veiculo_id, sistema, sintomas, ...)
except Exception as e:
    print(f"LLM falhou, usando mock: {e}")
    diagnostic = generate_mock_diagnostic(sistema, sintomas, km)
```

O professor pode verificar isso desligando a internet e submetendo uma ocorrÃªncia â€” o diagnÃ³stico ainda funciona (via mock).

---

## O que Funcionou

**Multi-agente com contexto compartilhado:** O historiador busca padrÃµes na frota e o diagnosticador usa essa informaÃ§Ã£o pra ajustar a probabilidade. Isso gera diagnÃ³sticos mais fundamentados do que um LLM Ãºnico.

**Fallback pro mock:** Quando a API do Gemini atingiu o rate limit, o sistema continuou funcionando com o mock. Pra um sistema de produÃ§Ã£o, esse tipo de resiliÃªncia Ã© essencial.

**SeparaÃ§Ã£o de responsabilidades:** Cada agente tem um prompt enxuto e focado. Prompt do diagnosticador nÃ£o precisa saber sobre custos, prompt do financeiro nÃ£o precisa saber sobre sintomas tÃ©cnicos. Isso melhora a qualidade de cada resposta.

**Tools consultando o banco real:** Os diagnÃ³sticos sÃ£o baseados em dados concretos (histÃ³rico de manutenÃ§Ãµes, saÃºde dos componentes), nÃ£o em conhecimento genÃ©rico do LLM.

---

## O que NÃ£o Funcionou

**Rate limit do Gemini:** O tier gratuito tem limites apertados. Em testes intensivos, a cota esgotou e o sistema caiu pro fallback. Em produÃ§Ã£o, precisaria de um plano pago ou modelo local.

**Parsing de JSON:** O Gemini Ã s vezes retorna markdown (```json ... ```) em volta do JSON, ou adiciona texto explicativo antes. Tive que implementar parsing manual que procura `{` e `}` no texto pra extrair o JSON.

**LatÃªncia do multi-agente:** 3-5 chamadas sequenciais ao Gemini somam 10-30 segundos. Pro usuÃ¡rio, Ã© perceptÃ­vel. Amenizei com execuÃ§Ã£o paralela (diagnosticador + historiador ao mesmo tempo), mas ainda Ã© mais lento que o mock.

**Tool calling com Gemini:** O tool calling do Gemini Ã© menos robusto que o do Claude. Ã€s vezes ignora tools disponÃ­veis e "adivinha" dados que deveria ter buscado. Simplifiquei as descriptions das tools pra serem mais diretas.

---

## Como Executar

### PrÃ©-requisitos
- Python 3.10+
- Node.js 18+
- Chave de API do Google Gemini (gratuita em https://aistudio.google.com/apikey)

### InstalaÃ§Ã£o

```bash
git clone https://github.com/RoseBorges44/fleetpred.git
cd fleetpred

# Configurar API key
cp backend/.env.example backend/.env
# Editar backend/.env e colocar sua GEMINI_API_KEY

# Terminal 1 â€” Backend:
cd backend
pip install -r requirements.txt
python -m uvicorn main:app --port 8000

# Terminal 2 â€” Frontend:
cd frontend
npm install
npm run dev
```

### Testar o Multi-Agente

1. Abrir http://localhost:5173
2. Ir em **"Registro OcorrÃªncia"**
3. Selecionar veÃ­culo **ABC-1234** (Scania R450, status crÃ­tico)
4. Km: **342100**
5. Sistema: **Motor**
6. Marcar: **"VibraÃ§Ã£o anormal"** e **"Perda de potÃªncia"**
7. Severidade: **Alta**
8. Clicar **"Enviar OcorrÃªncia"**

**No terminal do backend** deve aparecer:
```
[Orchestrator] Iniciando diagnÃ³stico â€” veÃ­culo 1, sistema Motor
[Orchestrator] VeÃ­culo 1 â€” modelo: Scania R450
[Diagnosticador] Analisando sintomas: ['VibraÃ§Ã£o anormal', 'Perda de potÃªncia']
[Historiador] Buscando histÃ³rico do veÃ­culo 1
[Historiador] Buscando padrÃµes na frota: Motor
[Planejador] Definindo urgÃªncia (severidade: alta)
[Financeiro] Calculando economia
[Orchestrator] DiagnÃ³stico consolidado em Xs
```

**Na tela** deve aparecer o diagnÃ³stico com:
- Componente identificado (ex: Turbocompressor)
- Probabilidade de falha (ex: 82%)
- Horizonte em dias (ex: 12)
- PeÃ§as sugeridas
- Economia estimada
- JSON completo da resposta

### Testar o Fallback

1. Renomear `backend/.env` pra `backend/.env.bak` (desativa a API key)
2. Reiniciar o backend
3. Submeter uma ocorrÃªncia
4. Deve funcionar usando o mock (terminal mostra "Usando fallback mock_ai")
5. Restaurar: renomear de volta pra `.env`

---

## Estrutura do Projeto

```
fleetpred/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI, CORS, registro de rotas
â”‚   â”œâ”€â”€ database.py          # Schema SQLite â€” 6 tabelas
â”‚   â”œâ”€â”€ seed_data.py         # 10 caminhÃµes com dados realistas
â”‚   â”œâ”€â”€ mock_ai.py           # Fallback quando LLM falha
â”‚   â”œâ”€â”€ .env.example         # Template da API key
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ agents/              # Sistema multi-agente
â”‚   â”‚   â”œâ”€â”€ orchestrator.py  # Orquestrador LangGraph
â”‚   â”‚   â”œâ”€â”€ diagnostician.py # Agente diagnosticador (temp 0.2)
â”‚   â”‚   â”œâ”€â”€ historian.py     # Agente historiador (temp 0.1)
â”‚   â”‚   â”œâ”€â”€ planner.py       # Agente planejador (temp 0.3)
â”‚   â”‚   â”œâ”€â”€ financial.py     # Agente financeiro (temp 0.1)
â”‚   â”‚   â””â”€â”€ llm_config.py   # Config Gemini
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â””â”€â”€ fleet_tools.py   # ImplementaÃ§Ã£o das tools (consulta banco)
â”‚   â””â”€â”€ routes/
â”‚       â”œâ”€â”€ veiculos.py
â”‚       â”œâ”€â”€ ocorrencias.py   # Chama orchestrator â†’ agentes â†’ banco
â”‚       â”œâ”€â”€ manutencoes.py
â”‚       â”œâ”€â”€ relatorios.py
â”‚       â””â”€â”€ alertas.py
â”œâ”€â”€ frontend/                # React + Vite (NÃƒO alterado na versÃ£o final)
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ orchestrator.txt     # Prompt do orquestrador
â”‚   â”œâ”€â”€ diagnostician.txt    # Prompt do diagnosticador
â”‚   â”œâ”€â”€ historian.txt        # Prompt do historiador
â”‚   â”œâ”€â”€ planner.txt          # Prompt do planejador
â”‚   â”œâ”€â”€ financial.txt        # Prompt do financeiro
â”‚   â””â”€â”€ DECISOES.md          # Justificativas de cada prompt
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ tool_definitions.json # DefiniÃ§Ãµes no formato JSON
â”‚   â””â”€â”€ DECISOES.md          # Justificativas das tools
â”œâ”€â”€ start.sh
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```
